

**Amazon EKS does *not* install Metrics Server by default.**

What that means in practice:

* A fresh EKS cluster **does not have `metrics-server`**
* Commands like:

  ```bash
  kubectl top nodes
  kubectl top pods
  ```

  will **fail** until you install it
* HPA (Horizontal Pod Autoscaler) that relies on CPU/memory **wonâ€™t work** without it

### What *is* installed by default in EKS

EKS gives you the control plane and a few core addons, but **Metrics Server is not one of them**. Typical defaults include:

* kube-proxy
* CoreDNS
* VPC CNI

### How people usually install it

Most teams install Metrics Server via:

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

Or as an **EKS add-on** (recommended for production):

```bash
aws eks create-addon \
  --cluster-name <cluster-name> \
  --addon-name metrics-server
```

### Quick check if itâ€™s already installed

```bash
kubectl get deployment metrics-server -n kube-system
```

If you want, tell me:

* EKS version
* Whether youâ€™re using managed node groups or Fargate

â€¦and Iâ€™ll tell you the **best install method + flags** for your setup.


Great question â€” this is one of those â€œit just worksâ€¦ until it doesnâ€™tâ€ components ğŸ˜„
Letâ€™s break it down **clearly and EKS-specific**.

---

## What Metrics Server *does*

**Metrics Server collects short-term CPU and memory usage** for:

* **Nodes**
* **Pods / containers**

It exposes this data through the Kubernetes **Metrics API** (`metrics.k8s.io`).

Thatâ€™s it.
ğŸ‘‰ It **does NOT** store historical data
ğŸ‘‰ It **does NOT** do alerting
ğŸ‘‰ It **does NOT** replace Prometheus

---

## Why it exists (what uses it)

Metrics Server is mainly used by:

### 1ï¸âƒ£ `kubectl top`

```bash
kubectl top nodes
kubectl top pods
```

Without Metrics Server â†’ these commands fail.

---

### 2ï¸âƒ£ Horizontal Pod Autoscaler (HPA)

HPA uses Metrics Server to decide:

* When to scale **up**
* When to scale **down**

Example:

```yaml
targetCPUUtilizationPercentage: 70
```

Metrics Server provides:

```
current CPU usage â†’ HPA â†’ scaling decision
```

---

## How Metrics Server works in **EKS**

Hereâ€™s the flow ğŸ‘‡

```
Kubelet (on each node)
   â†“
Metrics Server (kube-system)
   â†“
Metrics API (metrics.k8s.io)
   â†“
kubectl top / HPA
```

### Step-by-step

1. **Metrics Server runs as a Deployment** in `kube-system`
2. It **scrapes metrics from each nodeâ€™s kubelet**

   * Endpoint: `https://<node-ip>:10250/metrics/resource`
3. Kubelet gets CPU/memory from:

   * cAdvisor
   * container runtime (containerd in EKS)
4. Metrics Server:

   * Aggregates the data
   * Keeps it in memory (â‰ˆ last 1â€“5 minutes)
5. Exposes it via the **Kubernetes Aggregation Layer**

   * API: `metrics.k8s.io`

---

## Whatâ€™s EKS-specific about it

A few important EKS details:

### ğŸ” TLS & auth

* Metrics Server authenticates to kubelet using **RBAC**
* In EKS, you often need:

  ```yaml
  --kubelet-insecure-tls
  ```

  because node certificates may not match IP/DNS perfectly

(Managed add-on handles this for you ğŸ‘Œ)

---

### ğŸŒ Networking

* Metrics Server talks to nodes **inside the VPC**
* If using:

  * **Private clusters**
  * **Custom security groups**

  â†’ Node SG must allow traffic on **10250**

---

### ğŸ§  Data limitations

Metrics Server:

* Only near-real-time data
* No disk, network, or custom metrics
* No long-term storage

Thatâ€™s why people pair it with:

* **Prometheus**
* **CloudWatch Container Insights**

---

## What Metrics Server is *not*

Common misconception ğŸš«

| Thing              | Metrics Server         |
| ------------------ | ---------------------- |
| Monitoring         | âŒ                      |
| Alerting           | âŒ                      |
| Dashboards         | âŒ                      |
| Historical metrics | âŒ                      |
| Autoscaling        | âŒ (it only feeds data) |

Itâ€™s just a **metrics pipe**, not a monitoring system.

---

## Typical problems in EKS

If it breaks, youâ€™ll usually see:

```bash
kubectl top nodes
# error: Metrics API not available
```

Common causes:

* Missing `--kubelet-insecure-tls`
* Security group blocking 10250
* Node not Ready
* Metrics Server pod crashing

---

## When you *need* it

You **must** install Metrics Server if you use:

* HPA (CPU / memory)
* `kubectl top`
* Some autoscaling tools (KEDA CPU/memory mode)

You **donâ€™t need** it if:

* You only use Prometheus for observability
* No HPA based on CPU/memory

---

If you want, I can:

* Draw an **ASCII diagram** of the flow
* Show **real HPA â†’ Metrics Server â†’ Pod scaling**
* Compare **Metrics Server vs Prometheus vs CloudWatch**

Just say the word ğŸ‘Œ
Got it â€” hereâ€™s a **real, end-to-end example** of
**HPA â†’ Metrics Server â†’ Pod scaling** in an **EKS cluster** ğŸ‘‡

---

## 1ï¸âƒ£ The flow (big picture)

```
Pod CPU usage
   â†“
Kubelet (node)
   â†“
Metrics Server
   â†“
metrics.k8s.io API
   â†“
HPA controller
   â†“
Scale Deployment replicas
```

HPA checks metrics **every ~15 seconds** and decides whether to scale.

---

## 2ï¸âƒ£ Example app (CPU-based scaling)

### Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cpu-demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cpu-demo
  template:
    metadata:
      labels:
        app: cpu-demo
    spec:
      containers:
      - name: app
        image: nginx
        resources:
          requests:
            cpu: "100m"
            memory: "128Mi"
          limits:
            cpu: "500m"
            memory: "256Mi"
```

âš ï¸ **Important**
HPA **requires `resources.requests.cpu`** â€” without it, scaling wonâ€™t work.

---

## 3ï¸âƒ£ HPA definition (uses Metrics Server)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: cpu-demo-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: cpu-demo
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

### What this means

* Target: **70% CPU**
* CPU is calculated as:

  ```
  current CPU usage / requested CPU
  ```
* If average > 70% â†’ scale up
* If average < 70% â†’ scale down

---

## 4ï¸âƒ£ What Metrics Server provides (real numbers)

Metrics Server reports something like:

```
Pod A: 90m CPU
Pod B: 80m CPU
```

Requests:

```
100m CPU per pod
```

HPA calculation:

```
Average utilization =
(90 + 80) / (2 Ã— 100) = 85%
```

â¡ï¸ HPA decides to **scale up**

---

## 5ï¸âƒ£ Scaling happens (real behavior)

```bash
kubectl get hpa
```

Output:

```
NAME           REFERENCE             TARGETS   MINPODS   MAXPODS   REPLICAS
cpu-demo-hpa   Deployment/cpu-demo   85%/70%   1         5         2
```

HPA increases replicas:

```
1 â†’ 2 â†’ 3 â†’ ...
```

---

## 6ï¸âƒ£ After load drops (scale down)

HPA:

* Waits for **stabilization window** (default ~5 min)
* Re-checks metrics
* Gradually scales down

This prevents **flapping**.

---

## 7ï¸âƒ£ How often things happen

| Component             | Interval |
| --------------------- | -------- |
| Metrics Server scrape | ~15s     |
| HPA evaluation        | ~15s     |
| Scale down delay      | ~300s    |

---

## 8ï¸âƒ£ Common EKS gotchas (very real)

### âŒ HPA shows `unknown`

```bash
kubectl describe hpa cpu-demo-hpa
```

Usually means:

* Metrics Server not installed
* Pod missing `resources.requests.cpu`
* Metrics Server canâ€™t reach kubelet (10250 blocked)

---

### âŒ Scaling too aggressive

Fix with:

```yaml
behavior:
  scaleUp:
    stabilizationWindowSeconds: 60
  scaleDown:
    stabilizationWindowSeconds: 300
```

---

## 9ï¸âƒ£ Summary (mental model)

* **Metrics Server = data source**
* **HPA = decision maker**
* **Deployment = thing that actually scales**

Metrics Server never scales anything by itself â€” it just reports numbers.

---

If you want next:

* ğŸ”¥ **Load-test demo** (`stress` / `hey`)
* ğŸ§  **Memory-based HPA**
* ğŸš€ **Custom metrics (Prometheus + HPA)**

Tell me what you want to dive into next.
